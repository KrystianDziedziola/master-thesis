\chapter{Próba rozwi¹zania problemu}
\label{chapter_5}

\section{Proces uczenia}
Proces uczenia sieci neuronowej stworzony zosta³ w œrodowisku Jupyter Notebook, które umo¿liwia tworzenie dokumentów zawieraj¹cych opisy, wykresy oraz wykonywalne kody Ÿród³owe. Nazwa Jupyter wziê³a siê z tego, ¿e œrodowisko umo¿liwia pracê w trzech jêzykach: Julia, Python oraz R.

Dokument sk³ada siê z wielu komórek, które mog¹ byæ wywo³ywane niezale¿nie.
Przewag¹ kodu pisanego w tym œrodowisku nad tradycyjnymi skryptami jest oferowana przez nie mo¿liwoœæ zapamiêtywania stanu zmiennych. Dziêki temu nie ma potrzeby ka¿dorazowego wywo³ywania ca³ego kodu, a jedynie fragmentów, które w danej chwili s¹ potrzebne np. jednorazowe przygotowanie danych, a nastêpnie wykonywanie jedynie procesu uczenia.

Proces uczenia sk³ada siê z kilku kroków:
\begin{itemize}
	\item pobranie i przygotowanie danych za pomoc¹ przygotowanych skryptów \ref{data_preparation}
	\item podzia³ danych na zbiory s³u¿¹ce do nauki oraz testowania przy pomocy k-krotnej 
walidacji krzy¿owej \textit{(ang. k-fold cross-validation)} \ref{validation_method}
	\item utworzenie modelu sieci neuronowej \ref{build_model}
	\item rozpoczêcie uczenia modelu \ref{run_learning}
	\item sprawdzenie skutecznoœci i przedstawienie wyników \ref{verify_accuracy}
\end{itemize}

Wszystkie wymienione kroki przedstawiaj¹ pe³en proces uczenia, który pokazuje z jak¹ dok³adnoœci¹ model jest w stanie wykrywaæ stany padaczkowe.

\subsection{Przygotowanie danych}
\label{data_preparation}
W celu wykorzystania dostêpnych danych w procesie uczenia sieci neuronowej nale¿y je najpierw odpowiednio przygotowaæ.
Dostarczone zosta³y dane w postaci plików tekstowych z liczbami reprezentuj¹cymi wartoœci zmierzone przy pomocy elektroencofalogramu. W poszczególnych kolumnach znajduj¹ siê wartoœci odpowiadaj¹ce konkretnym kana³om (\textit{EEG\_FP1\_F3}, \textit{EEG\_FP2\_F4} itd.). Ostatnia kolumna (o nag³ówku \textit{t}) przedstawia czas w sekundach, w którym mia³ miejsce pomiar. 

Dostêpne s¹ dane 104 pacjentów, u których wyst¹pi³y ataki. Ka¿dy z nich posiada odczyty wykonane z czêstotliwoœci¹ 500Hz przez blisko 15 minut. Jest to oko³o 450 000 linii w ka¿dym pliku. Dane zajmuj¹ 6,5 GB.

Fragment jednego z plików z danymi wygl¹da nastêpuj¹co:

\begin{lstlisting}[caption=Dane liczbowe z odczytu EEG]
"EEG_FP1_F3"	"EEG_FP2_F4"	"EEG_F3_C3"	"EEG_F4_C4"	"EEG_C3_P3"	"EEG_C4_P4"	"EEG_P3_O1"	"EEG_P4_O2"	"EEG_FP1_F7"	"EEG_FP2_F8"	"EEG_F7_T3"	"EEG_F8_T4"	"EEG_T3_T5"	"EEG_T4_T6"	"EEG_T5_O1"	"EEG_T6_O2"	"t"
-1.7032	-3.3727	5.9014	2.512	2.6404	4.0193	16.9162	35.4401	5.3506	1.1355	-1.0843	-3.9932	9.4594	14.8409	10.0322	26.6143	0
-3.1702	-4.5883	5.8762	2.9638	3.5952	3.9019	17.1137	36.3634	4.3875	0.543	-1.356	-4.5697	10.309	14.1082	10.0724	28.5593	0.002
-4.2669	-5.2157	5.6852	3.1698	4.0053	3.6091	16.4135	36.7024	2.9881	0.4522	-1.7584	-5.4206	11.1134	13.3778	9.4926	29.8509	0.004
-4.8106	-5.2287	5.2889	2.6745	3.714	3.0257	14.9097	36.4086	1.6189	0.2802	-2.1206	-6.4522	11.2876	12.7727	8.3198	30.2831	0.006
-5.0684	-5.1176	4.7665	1.7354	2.9116	2.354	12.7327	35.6144	0.5718	-0.618	-2.57	-7.3378	10.6144	12.2487	6.7256	30.2934	0.008
-5.3637	-5.1568	4.399	1.03	1.764	1.9509	10.2011	34.6652	-0.2974	-2.1804	-3.1603	-7.7025	9.3368	11.727	5.1179	30.6433	0.01
\end{lstlisting}

Dodatkowo dostarczony zosta³ plik przechowuj¹cy wyznaczone przez lekarza momenty wyst¹pienia ataków dla ka¿dego z pacjentów. Plik w kolejnych wierszach zawiera punkty w czasie rozdzielone przecinkami (w sekundach).
Ka¿dy wiersz odpowiada jednemu pacjentowi, dlatego plik zawiera 104 wiersze. Fragment pliku z czasami wyst¹pienia ataków:
\begin{lstlisting}[caption=Punkty w czasie wyst¹pienia ataków]
835,853,865,873,889,908
18,48,110,309,466,618,757
216,239
44,329,501,559,622
36,190,406,576,714,754
158,510,917
622,653,676,737
\end{lstlisting}

W celu wykorzystania przedstawionych danych w procesie uczenia sieci neuronowej musz¹ zostaæ one odpowiednio przygotowane.
Wybrane podejœcie zak³ada podzielenie danych na okna czasowe o okreœlonej d³ugoœci. Znane s¹ jedynie pocz¹tki ataków, jednak nie wiadomo jak d³ugo trwa³y. D³ugoœæ okna czasowego, wed³ug którego podzielone zostan¹ dane bêdzie wiêc jednym z parametrów, który nale¿y dobraæ w celu uzyskania najlepszych rezultatów.

Do przygotowania danych stworzony zosta³ skrypt, który wykonuje nastêpuj¹ce czynnoœci:
\begin{itemize}
	\item wczytanie danych pacjentów oraz informacji o atakach
	\item przetworzenie danych do czêstotliwoœci 100Hz
	\item podzia³ danych na okna czasowe o d³ugoœci przekazanej jako parametr (w sekundach)
	\item normalizacja danych - œrednia 0, odchylenie standardowe 1
	\item konwersja danych dotycz¹cych ataków na postaæ tzw. "jeden z n" \textit{(ang. one-hot encoding)}
	\item wyœwietlanie informacji o postêpie przetwarzanych plików
	\item zapis pobranych danych do plików tymczasowych umo¿liwiaj¹cych szybszy odczyt
\end{itemize}

Technicznie skrypty zosta³y podzielone na 2 pliki:
\begin{itemize}
\item data\_reader.py
\item chunks\_creator.py
\end{itemize}
Pierwszy z nich zajmuje siê wczytywaniem i korzysta z drugiego w celu stworzenia okien czasowych.
G³ówn¹ funkcj¹ dostarczan¹ przez skrypt, która umo¿liwia wykonanie wszystkich wymienionych wy¿ej czynnoœci jest \textit{get\_data()}. Jako parametr przyjmuje ona czas w sekundach, który oznacza d³ugoœæ okna czasowego. Znajduje siê ona na koñcu pliku, gdy¿ z uwagi na specyfikê jêzyka wszystkie wykorzystywane przez ni¹ funkcje musz¹ byæ wczeœniej zadeklarowane. 
Kod skryptu pobieraj¹cego dane rozszerzony o komentarze opisuj¹ce poszczególne kroki zaprezentowany zosta³ na listingu \ref{lst:data-reader.py}.

\begin{lstlisting}[caption=data\_reader.py, language=Python, label={lst:data-reader.py}]
import os
import numpy as np
import pickle

from chunks_creator import prepare_chunks
from chunks_creator import flatten_chunks

from sklearn.preprocessing import StandardScaler

INPUT_DATA_FILE_PATH='tmp/input-{}sec.pckl'

DATA_FREQUENCY = 500
SAMPLING_RATE = 5
FREQUENCY_TO_SAMPLING_RATIO = DATA_FREQUENCY // SAMPLING_RATE


# Konwertuje plik z danymi pacjenta z postaci tekstowej do tablicowej oraz zmienia czêstotliwoœæ próbkowania do 100Hz
def parse_file(file, sampling_rate):
    lines = file.split('\n')
    headers = lines[0].split('\t')
    # to one before last because the last one is empty
    data = lines[1:-1]

    number_of_lines = len(data)

    float_data = np.zeros((number_of_lines, len(headers)))
    for line_number, line in enumerate(data):
        values = [float(value) for value in line.split('\t')]
        float_data[line_number, :] = values

    return float_data[::sampling_rate], headers


# Wczytuje dane pacjentów z dysku
def read_input_files(end, data_path, sampling_rate):
    input_path = os.path.join(data_path, 'input_500Hz/sick')
    input_file_names = os.listdir(input_path)
    input_file_names.sort(key=int)

    start = None

    files_content = []
    for file_name in input_file_names[start:end]:
        file_path = os.path.join(input_path, file_name)
        file = open(file_path, 'r')
        (columns, headers) = parse_file(file.read(), sampling_rate)
        print('Loaded input file:', file_name)
        file.close()
        files_content.append(columns)
    print('--Input files loaded--')
    return files_content, headers


def create_target_index(value, frequency_to_sampling_ratio):
    value = int(value)
    return int(value * frequency_to_sampling_ratio)


# Odczytuje informacje dotycz¹ce czasów ataków i konwertuje do postaci one-hot
def read_target_files(end, data_path, sampling_rate, data_frequency):
    frequency_to_sampling_ratio = data_frequency // sampling_rate
    targets_path = os.path.join(data_path, 'targets')
    targets_file_name = os.listdir(targets_path)[0]
    targets_file_path = os.path.join(targets_path, targets_file_name)

    file = open(targets_file_path, 'r')
    targets_content = file.read()
    file.close()

    lines = targets_content.split('\n')[:-1]
    targets = []
    for number, line in enumerate(lines, 1):
        targets.append([(int(value), create_target_index(value, frequency_to_sampling_ratio)) for value in line.split(',')])
    print('--Target files loaded--')
    return targets[:end]


# Pobiera dane pacjentów oraz czasy ataków
def read_data(data_path, sampling_rate, data_frequency, end=104):
    (input_data, headers) = read_input_files(end, data_path, sampling_rate)
    targets_data = read_target_files(end, data_path, sampling_rate, data_frequency)

    return input_data, targets_data, headers


# Odczytuje dane i zapisuje zmienne do pliku tymczasowego
def load_data_to_file(chunk_size_in_seconds):
    (input_data, target, headers) = read_data(data_path='data', 
                                              sampling_rate=SAMPLING_RATE, 
                                              data_frequency=DATA_FREQUENCY)

    with open(INPUT_DATA_FILE_PATH.format(chunk_size_in_seconds), 'wb') as input_variable_file:
        pickle.dump([input_data, target, headers], input_variable_file)

    del input_data, target, headers
    

# Normalizuje dane u¿ywaj¹c obiektu StandardScaler(). Zwrócone dane posiadaj¹ œredni¹ 0 oraz odchylenie standardowe 1.    
def normalize(x, y):
    scalers = {}
    for channel_number in range(x.shape[1]):
        scalers[channel_number] = StandardScaler()
        x[:, channel_number, :] = scalers[channel_number].fit_transform(x[:, channel_number, :]) 
    return x, y.astype(int)


# Pobiera zmienne z danymi z utworzonego pliku tymczasowego
def load_input_data(chunk_size_in_seconds):
    with open(INPUT_DATA_FILE_PATH.format(chunk_size_in_seconds), 'rb') as input_data_file:
        input_data, target, headers = pickle.load(input_data_file)
    
    return input_data, target, headers


# Pobiera dane wykorzystuj¹c funkcjê load_input_data() i wywo³uje funkcjê prepare_chunks() z pliku chunks_creator.py w celu utworzenia okien czasowych z danymi. Utworzone porcje danych s¹ nastêpnie poddawane normalizacji.
def prepare_data(chunk_size_in_seconds):
    input_data, target, headers = load_input_data(chunk_size_in_seconds)
    
    chunks_input, chunks_target = prepare_chunks(input_data, 
                                                target, 
                                                chunk_size_in_seconds=chunk_size_in_seconds, 
                                                ratio=FREQUENCY_TO_SAMPLING_RATIO)
    x, y = flatten_chunks(chunks_input, chunks_target)
    x, y = normalize(x, y)
    
    return x, y


# G³ówna funkcja skryptu, która zwraca odpowiednio przygotowane dane. Przy pierwszym uruchomieniu wczytuje dane z dysku do zmiennych i zapisuje je do pliku tymczasowego. Odczyt zmiennych z danymi z pliku binarnego umo¿liwia szybszy dostêp przy kolejnych uruchomieniach, gdy¿ otwieranie du¿ych plików tekstowych jest czasoch³onne.
def get_data(chunk_size_in_seconds):
    file_exists = os.path.isfile(INPUT_DATA_FILE_PATH.format(chunk_size_in_seconds))
    
    if not file_exists:
        load_data_to_file(chunk_size_in_seconds)
        
    return prepare_data(chunk_size_in_seconds)
\end{lstlisting}

Funkcja \textit{prepare\_data()} w powy¿szym skrypcie korzysta z osobnego pliku o nazwie \textit{chunks\_creator.py}, w którym zosta³y zdefiniowane funkcje tworz¹ce okna czasowe z danymi.
Dla danych ka¿dego z pacjentów tworzonych jest \textit{2 * n} okien czasowych, gdzie \textit{n} oznacza iloœæ zdiagnozowanych ataków. 

Porcje danych zawieracj¹ce ataki tworzone s¹ na pocz¹tku ka¿dego z nich i trwaj¹ przez okreœlony czas podany w parametrze. Nastêpnie tworzone jest \textit{n} kolejnych porcji danych zawieraj¹cych dane liczbowe z okresu, w którym nie wyst¹pi³ atak.
Utworzone okna czasowe zawieraj¹ wiêc proporcjonaln¹ iloœæ danych z atakami oraz bez.
Dodatkowo tworzona jest tablica zawieraj¹ca informacje o tym czy dla danego okna czasowego wyst¹pi³  \textit{(wartoœæ 1)} lub nie wyst¹pi³ \textit{(wartoœæ 0)} atak.

Implementacja skryptu odopowiadaj¹cego za przetwarzanie danych do postaci okien czasowych przedstawiona zosta³a na listlingu \ref{lst:chunks-creator.py}.

\begin{lstlisting}[caption=chunks\_creator.py, language=Python, label={lst:chunks-creator.py}]
import random
import numpy as np


# Tworzy porcje danych, w których wyst¹pi³y ataki.
def create_chunks_with_seizures(patient_data, seizure_seconds, chunk_size):
    number_of_chunks = len(seizure_seconds)

    chunks_input = np.zeros((number_of_chunks, chunk_size, 17))
    chunks_target = np.zeros(number_of_chunks)

    for seizure_number in range(0, number_of_chunks):
        (seizure_time, seizure_index) = seizure_seconds[seizure_number]
        chunk_start_index = seizure_index
        chunk_end_index = chunk_start_index + chunk_size
        chunks_input[seizure_number] = patient_data[chunk_start_index:chunk_end_index, :]
        # atak oznaczony wartoœci¹ '1'
        chunks_target[seizure_number] = 1

    return (chunks_input, chunks_target)


# Sprawdza czy podany fragment znajduje siê w zasiêgu ataku.
def is_in_seizure_range(index, seizure_seconds, chunk_size):
    for (seizure_time, seizure_index) in seizure_seconds:
        seizure_start_index = seizure_index
        seizure_end_index = seizure_start_index + chunk_size
        if index in range(seizure_start_index, seizure_end_index):
            return True

    return False


# Tworzy pocz¹tek pojedynczej porcji danych, który wybierany jest losowo, jednak sprawdzane jest, aby nie zawiera³a ona momentów, w których wyst¹pi³ atak.
def create_non_seizure_data_start_index(data_size, chunk_size, seizure_seconds):
    start_index = random.randint(0, data_size - chunk_size)

    while (is_in_seizure_range(start_index, seizure_seconds, chunk_size)):
        start_index = random.randint(0, data_size - chunk_size)

    return start_index


# Tworzy porcje danych, w których nie wyst¹pi³y ataki.
def create_chunks_without_seizures(patient_data, seizure_seconds, chunk_size):
    number_of_chunks = len(seizure_seconds)

    chunks_input = np.zeros((number_of_chunks, chunk_size, 17))
    chunks_target = np.zeros(number_of_chunks)
    (data_size, channels) = patient_data.shape

    for chunk_number in range(0, number_of_chunks):
        chunk_start_index = create_non_seizure_data_start_index(data_size, chunk_size, seizure_seconds)

        chunk_end_index = chunk_start_index + chunk_size
        chunks_input[chunk_number] = patient_data[chunk_start_index:chunk_end_index, :]
        # brak ataku oznaczone wartoœci¹ '0'
        chunks_target[chunk_number] = 0

    return (chunks_input, chunks_target)


# Przystosowuje iloœæ wymiarów danych do procesu uczenia sieci neuronowej.
def flatten_chunks(chunks_input, chunks_target):
    train_input = []
    train_target = []

    for patient_number in range(0, len(chunks_input)):
        patient_data = chunks_input[patient_number]
        patient_targets = chunks_target[patient_number]
        for chunk_number in range(0, len(patient_data)):
            train_input.append(patient_data[chunk_number])
            train_target.append(patient_targets[chunk_number])

    train_input = np.array(train_input)
    train_target = np.array(train_target)

    train_input = train_input[:, :, :-1]
    
    return train_input, train_target 


# G³ówna funkcja skryptu zwracaj¹ca okna czasowe stworzone z danych pacjentów w postaci wielowymiarowej tablicy oraz tablicê zawieraj¹c¹ informacje o wyst¹pieniu ataków.
def prepare_chunks(input, target, chunk_size_in_seconds, ratio):
    chunk_size = chunk_size_in_seconds * ratio
    chunks_input = []
    chunks_target = []

    for patient_number in range(0, len(input)):
        patient_chunks_input = []
        patient_chunks_target = []
        seizure_seconds = target[patient_number]
        patient_data = input[patient_number]
        (seizure_chunks_input, seizure_chunks_target) = create_chunks_with_seizures(patient_data,seizure_seconds, chunk_size)
        patient_chunks_input.extend(seizure_chunks_input)
        patient_chunks_target.extend(seizure_chunks_target)

        (non_seizure_chunks_input, non_seizure_chunks_target) = create_chunks_without_seizures(patient_data, seizure_seconds, chunk_size)
        patient_chunks_input.extend(non_seizure_chunks_input)
        patient_chunks_target.extend(non_seizure_chunks_target)

        chunks_input.append(np.array(patient_chunks_input))
        chunks_target.append(np.array(patient_chunks_target))

    return np.array(chunks_input), np.array(chunks_target)

\end{lstlisting}

Przedstawione skrypty umo¿liwiaj¹ pobranie odpowiednio przygotowanych danych, które nastêpnie mog¹ byæ u¿yte w procesie uczenia sieci neuronowej.

\subsection{Metoda oceny wyników}
\label{validation_method}
Do zweryfikowania skutecznoœci modelu wymagane jest podzielenie danych na odpowiednie zbiory. Korzystanie z jednego, identycznego zbioru danych do nauki oraz testowania jest b³êdem, gdy¿ mo¿e wprowadziæ z³udne wra¿enie, ¿e model posiada bardzo dobr¹ skutecznoœæ. Sieæ neuronowa, której dzia³anie weryfikowane jest na danych, które pos³u¿y³y do nauki bêdzie posiadaæ skutecznoœæ blisk¹ 100\%. Dzieje siê tak dlatego, ¿e umie ona rozpoznawaæ te konkretne dane, gdy¿ zna dla nich wartoœci wyjœciowe, które podane zosta³y podczas nauki. W ten sposób nauczony model bêdzie natomiast posiada³ bardzo nisk¹ skutecznoœæ, gdy na jego wejœcie podane zostan¹ dane, które nigdy wczeœniej nie zosta³y mu przedstawione.
W ka¿dym rodzaju uczenia maszynowego d¹¿y siê do uzyskania jak najwiêkszej zdolnoœci generalizacji, czyli skutecznoœci klasyfikacji danych, które nie zosta³y nigdy wczeœniej przekazane do modelu. Przeciwieñstwem tego jest tzw. "nadmierne dopasowanie" \textit{(ang. overfitting)}, czyli sytuacja, w której model zbytnio dopasowuje siê do danych ucz¹cych, co powoduje bardzo s³ab¹ zdolnoœæ generalizacji. Zjawisko to jest g³ównym problemem podczas uczenia modelu.

\subsubsection{Hold-out}
Podstawowym sposobem oceny wyników jest podzielenie danych na dwa zbiory: treningowy oraz testowy \textit{(ang. hold-out)}. Mo¿na dzieliæ je w ró¿nych proporcjach np. 80/20, 90/10, 95/5 itp. w zale¿noœci od iloœci posiadanych danych. Przy niewielkich zbiorach wydzielenie zbyt du¿ej liczby danych do zbioru testowego mo¿e powodowaæ niedobory w procesie nauki. Wydzielenie jedynie dwóch zbiorów danych nie rozwi¹zuje jednak do koñca problemu \textit{overfitting}'u, gdy¿ zbyt czêsta zmiana modelu i sprawdzanie jego skutecznoœci na danych testowych mo¿e spowodowaæ zbyt du¿e dopasowanie do zbioru testowego \cite{Chollet:2018}. Z tego wzglêdu czêsto stosowany jest dodatkowy zbiór walidacyjny \textit{(ang. validation set)}. W tym podejœciu model uczony jest na danych treningowych, sprawdzany na danych walidacyjnych i na podstawie tych wyników wprowadza siê modyfikacje w modelu. Zbiór testowy s³u¿y jedynie do ostatecznego sprawdzenia skutecznoœci modelu, gdy¿ s¹ to dane, które nigdy wczeœniej nie zosta³y u¿yte w procesie nauki. Dane dzielone s¹ w proporcjach np. 80/10/10, 90/5/5. Schemat tego podejœcia przedstawiony jest na rysunku \ref{fig:hold-out-validation}

\begin{figure}[h!]
	\centering
	\includegraphics[width=9cm]{Rysunki/Rozdzial5/hold-out-validation.pdf}
	\caption{Podzia³ danych na zbiory: treningowy, walidacyjny i testowy}
	\label{fig:hold-out-validation}
\end{figure}

Metoda ta rozwi¹zuje problem zbytniego dopasowywania siê do zbioru testowego, jednak równie¿ posiada drug¹ wadê poprzedniego rozwi¹zania. Przy niewielkiej iloœci danych wydzielanie osobnych zbiorów mo¿e spowodowaæ, ¿e zbiór ucz¹cy bêdzie zbyt ma³y. W celu unikniêcia tego problemu mo¿na zastosowaæ tzw. walidacjê krzy¿ow¹ i jej iteracyjne rozszerzenie.


\subsubsection{Walidacja krzy¿owa}
Kolejn¹ metod¹ walidacji jest tzw. \textit{k}-krotna walidacja krzy¿owa \textit{(ang. k-fold cross-validation)}. Tak samo jak w przypadku metody \textit{holdout} nale¿y najpierw wydzieliæ zbiór testowy, który nie bêdzie bra³ udzia³u w procesie uczenia i walidacji. Pozosta³e dane dzielone s¹ na \textit{k} zbiorów, przewa¿nie jest to \textit{k = 5} lub \textit{k = 10}. Nastêpnie \textit{k}-krotnie powtarzany jest proces wyboru jednego \textit{i}-tego zbioru, gdzie \textit{i} oznacza kolejne liczby z przedzia³u \textit{<1; k>}. Zbiór o numerze \textit{i} wybierany jest jako zbiór walidacyjny, natomiast reszta \textit{k - 1} zbiorów s³u¿¹ jako dane ucz¹ce. Nale¿y pamiêtaæ, ¿eby w ka¿dym przebiegu uczyæ now¹ instancjê modelu. W rezultacie model uczony jest \textit{k}-krotnie na ró¿nych kombinacjach danych. Jako wynik koñcowy brana jest pod uwagê œrednia skutecznoœæ wszystkich modeli. Sposób podzia³u danych w tej metodzie ilustruje rysunek \ref{fig:cross-validation}.

\begin{figure}[h!]
	\centering
	\includegraphics[width=14cm]{Rysunki/Rozdzial5/cross-validation.pdf}
	\caption{Podzia³ danych wed³ug metody k-krotnej walidacji krzy¿owe}
	\label{fig:cross-validation}
\end{figure}

Przedstawion¹ metodê mo¿na rozszerzyæ do jej iteracyjnej wersji polegaj¹cej na tym, ¿e ca³y proces \textit{k}-krotnej walidacji krzy¿owej wykonywany jest \textit{n} razy. Dodatkowo po ka¿dej iteracji mo¿na zastosowaæ mieszanie danych. Walidacja t¹ metod¹ co prawda trwa o wiele d³u¿ej, gdy¿ model walidowany jest \textit{k * n} razy, jednak pozwala uzyskaæ bardziej wiarygodne wyniki, gdy nie jest dostêpna zbyt du¿a liczba danych.

\subsubsection{Implementacja walidacji}
\label{crossvalidation_implementation}
Zaimplementowane zosta³y obie metody podzia³u danych, jednak ze wzglêdu na swoje zalety metody iteracyjnej \textit{k}-krotnej walidacji krzy¿owej to w³asnie ona zosta³a u¿yta do walidacji w procesie uczenie. Podzia³ danych wed³ug obu metod zosta³ wykonany za pomoc¹ biblioteki \textit{sklearn}, która dostarcza przygotowane do tego celu funkcje \ref{lst:split}.
\begin{lstlisting}[caption=Podzia³ danych na zbiory, language=Python, label={lst:split}]
from sklearn.model_selection import train_test_split, StratifiedKFold
from data_reader import get_data

def load_data_kfold(folds_number, test_size=0.05)):
    x, y = get_data(CHUNK_SIZE_IN_SECONDS)
    
    x_train, x_test, y_train, y_test = train_test_split(x, 
                                                        y, 
                                                        test_size=test_size)
    
    folds = list(StratifiedKFold(n_splits=folds_number, 
                                 shuffle=True, 
                                 random_state=1).split(x_train, y_train))
    
    return folds, x_train, y_train, x_test, y_test

def load_data_train_test(test_size=0.05):
    x, y = get_data(CHUNK_SIZE_IN_SECONDS)
    
    x_train, x_test, y_train, y_test = train_test_split(x, 
                                                        y, 
                                                        test_size=test_size)
    
    return x_train, y_train, x_test, y_test
\end{lstlisting}

Tak przygotowane dane podawane s¹ do modelu w \textit{n} iteracjach za pomoc¹ prostej pêtli. Wyniki z ka¿dej iteracji zapisywane s¹ do tablicy, a na koniec obliczana jest ich œrednia. Proces iteracyjnego uruchamiania uczenia wraz z obliczaniem wyników zaprezentowany zosta³ na listingu \ref{lst:iteration_learning}

\begin{lstlisting}[caption=Iterecyjne wywo³anie procesu uczenia, language=Python, label={lst:iteration_learning}]
number_of_iterations = 5

avg_accuracies = []
std_accuracies = []

for iteration in range(0, number_of_iterations):
    iteration_number = iteration + 1 
    print("Iteration", iteration_number)
    
    score, best_model_score = run_pipeline(create_model=model,
                                           folds=folds,
                                           x=x_train,
                                           y=y_train,
                                           epochs=100)

    accuracy = [row[1] for row in best_model_score]

    avg_accuracy = np.mean(accuracy)
    print("Best models average validation accuracy: {}".format(round(avg_accuracy, 6)))
    
    avg_accuracies.append(avg_accuracy)
   
grand_mean_avg = np.mean(avg_accuracies)
print("~~~Grand mean of average accuracy: {}".format(round(grand_mean_avg, 6)))
\end{lstlisting}

Do uruchamiania procesu uczenia u¿ywana jest funkcja \textit{run\_pipeline}, która szczegó³owo opisana zostanie w rozdziale \ref{run_learning}.

\subsection{Uruchomienie uczenia w³aœciwego}
\label{run_learning}
Do uruchomienia procesu uczenia w³aœciwego s³u¿y funkcja \textit{run\_pipeline()}, która wykonuje nastêpuj¹ce czynnoœci:
\begin{itemize}
\item tworzy model na podstawie dostarczonych specyfikacji (\ref{build_model})
\item pobiera odpowiednie porcje danych dla ka¿dego kroku z przytogowanych wczeœniej zbiorów (\ref{crossvalidation_implementation})
\item tworzy listê tzw. \textit{callback}'ów (\ref{callbacks})
\item uruchamia na modelu metodê s³u¿¹c¹ do dopasowania, która rozpoczyna uczenie (\ref{fit})
\item wczytuje wagi najlepszego modelu i sprawdza jego skutecznoœæ (\ref{verify_accuracy})
\end{itemize}

Ca³e cia³o metody \textit{run\_pipeline} zaprezentowane zosta³o na listingu \ref{lst:run-pipeline}. Poszczególne kroki zostan¹ opisane w kolejnych rozdzia³ach.

\begin{lstlisting}[caption=Implementacja metody uruchamiaj¹cej uczenie w³aœciwe, language=Python, label={lst:run-pipeline}]
def run_pipeline(create_model, folds, x, y, epochs):
    best_model_score = []
    
    for fold_number, (train_idx, val_idx) in enumerate(folds):
        print('\nFold: ', fold_number)
        # wybór odpowiednich podzbiorów
        x_train_cv = x[train_idx]
        y_train_cv = y[train_idx]
        x_valid_cv = x[val_idx]
        y_valid_cv = y[val_idx]
                
        input_shape = x.shape[1:]

        # stworzenie modelu
        model, model_description = create_model(input_shape)

        # utworzenie callback'ów
        callbacks = callbacks_list("{}. Fold: {}.".format(model_description, 
                                                          fold_number))
        # rozpoczêcie uczenia
        history = model.fit(x_train_cv,
                            y_train_cv,
                            epochs=epochs,
                            batch_size=16,
                            callbacks=callbacks,
                            validation_data=(x_valid_cv, y_valid_cv),
                            verbose=0)

        # wczytanie wag najlepszego modelu i sprawdzenie jego skutecznoœci
        model.load_weights("tmp/best_model.h5")
        best_model_score.append(model.evaluate(x_valid_cv, y_valid_cv, batch_size=16, verbose=0))
        print("--Best model validation accuracy: %.2f%%" % (best_model_score[fold_number][1]*100))
        
    return best_model_score
\end{lstlisting}

\subsubsection{Budowa modelu}
\label{build_model}
Model tworzony jest na podstawie dostarczonych specyfikacji w postaci funkcji. Funkcja zawiera kroki buduj¹ce model z kolejnych warstw, które dostêpne s¹ jako gotowe komponenty z biblioteki Keras. Ka¿da z warstw jest parametryzowana wybranymi wartoœciami. 
Po utworzeniu modelu jest on kompilowany. Na tym etapie podawane s¹ równie¿ informacje odnoœnie tego jaki optymalizator, funkcja strat oraz metryka skutecznoœci ma zostaæ u¿yta. Dodatkowo tworzony jest równie¿ opis modelu wykorzystywany póŸniej w procesie monitorowania.

Na listingu \ref{lst:model-example} zosta³a zaprezentowana funkcja tworz¹ca przyk³adowy model splotowej sieci neuronowej z 1-wymiarowym filtrem.

\begin{lstlisting}[caption=Tworzenie przyk³adowego modelu, language=Python, label={lst:model-example}]
def conv_1D_with_adam(input_shape):
    # opis modelu tworzony na podstawie nazwy funkcji
    description = get_function_name()
    
    # specyfikacja modelu tworzonego sekwencyjnie
    model = Sequential()

    # dodanie warstwy splotowej z 32 1-wymiarowymi filtrami o rozmiarze 6 z funkcj¹ aktywacji 'relu'
    model.add(Conv1D(filters=32, kernel_size=6, padding='same', activation='relu', input_shape=input_shape))
    # warstwa max pooling'u o rozmiarze 2
    model.add(MaxPooling1D(pool_size=2))

    # warstwa zmniejszaj¹ca liczbê wymiarów danych
    model.add(Flatten())
    # warstwa typu 'fully-connected' o rozmiarze 64 neuronów
    model.add(Dense(64, activation='relu'))
    # warstwa typu 'fully-connected' z jednym neuronem i sigmoidaln¹ funkcj¹ aktywacji, która na wyjœciu zwróci wartoœæ '0' lub '1'
    model.add(Dense(1, activation='sigmoid'))

    # kompilacja modelu z u¿yciem optymalizatora Adam, funkcji strat binarnej entropii krzy¿owej oraz dok³adnoœci (accuracy) jako metryki
    model.compile(optimizer=Adam(),                  
                  loss='binary_crossentropy',
                  metrics=['acc'])
 
    return model, description
\end{lstlisting}

\subsubsection{Lista callback'ów}
\label{callbacks}
Dodatkowym parametrem przekazywanym do procesu uczenia jest lista tzw. \textit{callback}'ów, czyli wywo³añ zwrotnych, które umo¿liwiaj¹ otrzymywanie informacji z wnêtrza modelu podczas jego nauki.

Zosta³y utworzone 4 nastêpuj¹ce callbacki:
\begin{itemize}
\item \textbf{EarlyStopping} - pozwala na wczeœniejsze zatrzymanie procesu uczenia w przypadku, gdy monitorowana metryka nie zosta³a poprawiona przez okreœlon¹ iloœæ epok
\item \textbf{LearningRateScheduler} - implementuje adaptacyjn¹ metodê zmiany wspó³czynnika uczenia wed³ug podanych regu³
\item \textbf{ModelCheckpoint} - umo¿liwia zapisanie modelu, który posiada najlepsze dopasowanie wed³ug okreœlonej metryki
\item \textbf{TensorBoard} - tworzy logi z procesu uczenia w podanym folderze, które mog¹ byæ u¿yte do monitorowania przez narzêdzie TensorBoard \ref{monitoring}
\end{itemize}


Listing \ref{lst:callback} przedstawia implementacjê metod tworz¹cych \textit{callback}'i.

\begin{lstlisting}[caption=Tworzenie listy \textit{callback}'ów, language=Python, label={lst:callback}]
def step_decay(epoch):    
    initial_lrate=0.1
    drop=0.6
    epochs_drop = 10.0
    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))
    
    return lrate


def callbacks_list(description): 
    return [
    callbacks.EarlyStopping(
        monitor='val_acc', 
        patience=30
    ),
    callbacks.LearningRateScheduler(step_decay),
        
    callbacks.ModelCheckpoint(
        filepath='tmp/best_model.h5', 
        monitor='val_acc',
        save_best_only=True
    ),
    callbacks.TensorBoard(
        log_dir='tmp/logs/{}. {}'.format(description, create_current_time()),
        histogram_freq=0,
        write_graph=True,
        write_images=True
    )
]
\end{lstlisting}

\subsubsection{Funkcja dopasowania}
\label{fit}
Wykonywana na modelu funkcja \textit{fit()} rozpoczyna procedurê uczenia, czyli dopasowania do danych.
Jako argumenty przykazywane s¹ do niej dane treningowe i walidacyjne, liczba epok ucz¹cych, \textit{callback}'i oraz inne parametry. Podczas nauki wyœwietlane s¹ informacje o postêpie uczenia oraz zwracany jest raport zawieraj¹cy historiê wartoœci metryk w kolejnych epokach, na podstawie których mo¿na np. narysowaæ wykres przedstawiaj¹cy postêpy.
Te wartoœci nie bêd¹ jednak u¿ywane, gdy¿ ca³a historia i postêpy uczenia s¹ ³adowane do programu monitoruj¹cego TensorBoard z logów tworzonych przez callback TensorBoard \ref{monitoring}.
Dodatkowo dla ka¿dej iteracji zapisywany jest najlepszy model, który na sam koniec zostanie za³adowany i sprawdzony pod k¹tem skutecznoœci \ref{verify_accuracy}.

\begin{lstlisting}[caption=Wywo³anie metody \textit{fit()} na modelu, language=Python, label={lst:fit}]
history = model.fit(x_train_cv,
                    y_train_cv,
                    epochs=epochs,
                    batch_size=16,
                    callbacks=callbacks,
                    validation_data=(x_valid_cv, y_valid_cv),
                    verbose=0)
\end{lstlisting}

\subsubsection{Sprawdzenie skutecznoœci}
\label{verify_accuracy}
W celu sprawdzenia skutecznoœci wczytywany jest najlepiej dopasowany model z danej iteracji i jest on sprawdzany metod¹ \textit{evaluate()} na danych walidacyjnych. Wynik jest nastêpnie wyœwietlany i zapisywany do tablicy, która pos³u¿y do policzenia œredniej skutecznoœci modelu. Przedstawione dzia³ania wykonuje kod zaprezentowany na listingu \ref{lst:validation}

\begin{lstlisting}[caption=Sprawdzenie skutecznoœci najlepszego modelu, language=Python, label={lst:validation}]
model.load_weights("tmp/best_model.h5")
best_model_score.append(model.evaluate(x_valid_cv, y_valid_cv, batch_size=16, verbose=0))
        
print("--Best model validation accuracy: %.2f%%" % (best_model_score[fold_number][1]*100))
\end{lstlisting}


\section{Monitorowanie}
\label{monitoring}
Model sieci neuronowej po zakoñczeniu procesu nauki zwraca obiekt zawieraj¹cy raport z wynikami. W sytuacji gdy proces uczenia przeprowadzany jest kilkukrotnie nale¿a³oby rêcznie zarz¹dzaæ obiektami raportów. Dodatkowo, przedstawienie wyników w sposób czytelny i ³atwy do zinterpretowania wymaga zaimplementowania metod wizualizacyjnych np. rysowanie wykresu. Nie ma jednak potrzeby rêcznej implementacji wy¿ej wymienionych funkcjonalnoœci, gdy¿ istniej¹ dedykowane narzêdzia umo¿liwiaj¹ce prezentacjê wyników w czasie rzeczywistym w przyjaznej dla u¿ytkownika formie.

Do monitorowania procesu uczenia zosta³o u¿yte narzêdzie \textit{TensorBoard}, które dostarczone jest razem z bibliotek¹ \textit{TensorFlow}. Pozwala ono m.in. na graficzn¹ wizualizacjê postêpów w procesie uczenia oraz automatyczne generowanie schematu modelu sieci neuronowej. Jest to narzêdzie uruchamiane w przegl¹darce, które wykorzystuje logi wygenerowane przez \textit{callback.TensorBoard} omawiany w rozdziale \ref{callbacks}. 

Na najprostszym widoku widoczne s¹ 4 wykresy ilustruj¹ce nastêpuj¹ce wartoœci:
\begin{itemize}
\item \textbf{acc} - dok³adnoœæ w procesie uczenia
\item \textbf{loss} - wartoœæ funkcji strat w procesie uczenia
\item \textbf{val\_acc} - dok³adnoœæ w procesie walidacji
\item \textbf{val\_loss} - wartoœæ funkcji strat w procesie walidacji
\end{itemize}
Wykresy zosta³y zaprezentowane na rysunku \ref{fig:tensor-board}. S¹ one interaktywe, wiêc mo¿na sprawdziæ dok³adn¹ wartoœæ w ka¿dym punkcie wykresu.
\begin{figure}[h!]
	\centering
	\includegraphics[width=12cm]{Rysunki/Rozdzial5/tensor-board.png}
	\caption{Dynamicznie tworzone wykresy w programie TensorBoard}
	\label{fig:tensor-board}
\end{figure}

Wizualna reprezentacja utworzonego modelu równie¿ mo¿e byæ pomocna przy ocenie architektury tworzonej sieci neuronowej. Fragment przyk³adowego schematu wygenerowany przez TensorBoard na podstawie modelu utworzonego w kodzie pokazany zosta³ na rysunku \ref{fig:tensor-board-model}.

\begin{figure}[h!]
	\centering
	\includegraphics[width=8cm]{Rysunki/Rozdzial5/tensor-board-model.png}
	\caption{Fragment schematu modelu wygenerowany przez TensorBoard}
	\label{fig:tensor-board-model}
\end{figure}

TensorBoard udostêpnia równie¿ wiele innych funkcjonalnoœci, które nie zosta³y u¿yte jak np. rysowanie wykresów w³asnorêcznie zdefiniowanych metryk, monitorowanie i wizualizacjê wag poszczególnych neuronów itp. Wiêcej informacji na temat mo¿liwoœci TensorBoard mo¿na znaleŸæ w dokumentacji \cite{tensor_board}. 

\section{Wybór rodzaju sieci neuronowej}
\section{Optymalizacja}
\section{Ocena otrzymanych rezultatów}