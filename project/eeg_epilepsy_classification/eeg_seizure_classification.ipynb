{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "* modify pipeline, more options\n",
    "* test data as whole, not couple of chunks\n",
    "* visualisation for diagnosing\n",
    "\n",
    "\n",
    "Architectures:\n",
    "* conv2d\n",
    "* cnn + lstm: https://stats.stackexchange.com/questions/252095/sequence-classification-via-neural-networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#display all values from array\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "#display not in scientific format\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Flatten, Dropout, LSTM, BatchNormalization, Activation\n",
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "from keras import callbacks\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "CHUNK_SIZE_IN_SECONDS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import datetime\n",
    "\n",
    "def create_current_time():\n",
    "    timestamp = time()\n",
    "    return datetime.datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "def end_time(start_time):\n",
    "    end_time = time() - start_time\n",
    "    return round(end_time, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "def get_function_name():\n",
    "    return inspect.stack()[1][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_reader import get_data\n",
    "\n",
    "def load_data_kfold(folds_number):\n",
    "    x, y = get_data(CHUNK_SIZE_IN_SECONDS)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, \n",
    "                                                        y, \n",
    "                                                        test_size=0.05)\n",
    "    \n",
    "    folds = list(StratifiedKFold(n_splits=folds_number, \n",
    "                                 shuffle=True, \n",
    "                                 random_state=1).split(x, y))\n",
    "    \n",
    "    return folds, x, y\n",
    "\n",
    "def load_data_train_test(test_size=0.05):\n",
    "    x, y = get_data(CHUNK_SIZE_IN_SECONDS)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, \n",
    "                                                        y, \n",
    "                                                        test_size=test_size)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):    \n",
    "    initial_lrate=0.1\n",
    "    drop=0.6\n",
    "    epochs_drop = 3.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    \n",
    "    return lrate\n",
    "\n",
    "\n",
    "def callbacks_list(description): \n",
    "    return [\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=10\n",
    "    ),\n",
    "    callbacks.LearningRateScheduler(step_decay),\n",
    "        \n",
    "    callbacks.ModelCheckpoint(\n",
    "        filepath='tmp/best_model.h5', \n",
    "        monitor='val_loss', \n",
    "        save_best_only=True\n",
    "    ),\n",
    "    callbacks.TensorBoard(\n",
    "        log_dir='tmp/logs/{}. {}'.format(description, create_current_time()),\n",
    "        histogram_freq=0, #it has to be 0, otherwise throws error during training\n",
    "        write_graph=True,\n",
    "        write_images=True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(create_model, folds, x, y, epochs):\n",
    "    score = []\n",
    "    best_model_score = []\n",
    "    \n",
    "    for fold_number, (train_idx, val_idx) in enumerate(folds):\n",
    "        print('\\nFold: ', fold_number)\n",
    "        x_train_cv = x[train_idx]\n",
    "        y_train_cv = y[train_idx]\n",
    "        x_valid_cv = x[val_idx]\n",
    "        y_valid_cv = y[val_idx]\n",
    "                \n",
    "        input_shape = x.shape[1:]\n",
    "\n",
    "        model, model_description = create_model(input_shape)\n",
    "\n",
    "        callbacks = callbacks_list(\"{}. Fold: {}.\".format(model_description, \n",
    "                                                         fold_number))\n",
    "\n",
    "        history = model.fit(x_train_cv,\n",
    "                            y_train_cv,\n",
    "                            epochs=epochs,\n",
    "                            batch_size=16,\n",
    "                            callbacks=callbacks,\n",
    "                            validation_data=(x_valid_cv, y_valid_cv),\n",
    "                            verbose=0)\n",
    "\n",
    "        score.append(model.evaluate(x_valid_cv, y_valid_cv, batch_size=16, verbose=0))\n",
    "\n",
    "        model.load_weights(\"tmp/best_model.h5\")\n",
    "        best_model_score.append(model.evaluate(x_valid_cv, y_valid_cv, batch_size=16, verbose=0))\n",
    "        \n",
    "        print(\"--Last epoch validation accuracy: %.2f%%\" % (score[fold_number][1]*100))\n",
    "        print(\"--Best model validation accuracy: %.2f%%\" % (best_model_score[fold_number][1]*100))\n",
    "        \n",
    "    return score, best_model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1176, 200, 16, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds, x, y = load_data_kfold(folds_number=10)\n",
    "\n",
    "# add dimmension for conv2d\n",
    "x3d = x\n",
    "x3d = np.expand_dims(x3d, axis=3)\n",
    "x3d.shape\n",
    "\n",
    "# x_train, y_train, x_test, y_test = load_data_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#75%\n",
    "def conv_1D_smaller_32_16_with_adam(input_shape):\n",
    "    description = get_function_name()\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=6, padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(Conv1D(filters=16, kernel_size=6, padding='same', activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "#     lr=3e-5\n",
    "    model.compile(optimizer=Adam(),                  \n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['acc'])\n",
    "    \n",
    "    return model, description\n",
    "\n",
    "\n",
    "# bad\n",
    "def cnn_lstm(input_shape):\n",
    "    description = get_function_name()\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=6, padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(Conv1D(filters=16, kernel_size=6, padding='same', activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(LSTM(100))\n",
    "    \n",
    "#     model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer=RMSprop(lr=3e-5),\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['acc'])\n",
    "    \n",
    "    return model, description\n",
    "\n",
    "\n",
    "def dense(input_shape):\n",
    "    description = get_function_name()\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=input_shape))\n",
    "    model.add(Dense(1000, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    \n",
    "    sgd = SGD(lr=0.1, momentum=0.9, decay=0.0, nesterov=False)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    return model, description\n",
    "\n",
    "\n",
    "def testing(input_shape):\n",
    "    description = get_function_name()\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=6, padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(Conv1D(filters=16, kernel_size=6, padding='same', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "#     lr=3e-5\n",
    "    model.compile(optimizer=Adam(),                  \n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['acc'])\n",
    "    \n",
    "    return model, description\n",
    "\n",
    "# 78%\n",
    "def conv_2D(input_shape):\n",
    "    description = get_function_name()\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(64,(3,3),strides = (1,1),name='layer_conv1',padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2,2),name='maxPool1'))\n",
    "    \n",
    "    model.add(Conv2D(64,(3,3),strides = (1,1),name='layer_conv2',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2,2),name='maxPool2'))\n",
    "    \n",
    "    model.add(Conv2D(32,(3,3),strides = (1,1),name='conv3',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2,2),name='maxPool3'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64,activation = 'relu',name='fc0'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(32,activation = 'relu',name='fc1'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "#         optimizer=Adam(),                  \n",
    "        optimizer=SGD(lr=0.01, momentum=0.5, decay=0.0, nesterov=False), \n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['acc'])\n",
    "    \n",
    "    return model, description\n",
    "\n",
    "\n",
    "# 78%\n",
    "def conv_2D_smaller(input_shape):\n",
    "    description = get_function_name()\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(64,(3,3),strides = (1,1),name='layer_conv1',padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2,2),name='maxPool1'))\n",
    "    \n",
    "#     model.add(Conv2D(64,(3,3),strides = (1,1),name='layer_conv2',padding='same'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling2D((2,2),name='maxPool2'))\n",
    "    \n",
    "    model.add(Conv2D(32,(3,3),strides = (1,1),name='conv3',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2,2),name='maxPool3'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64,activation = 'relu',name='fc0'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(32,activation = 'relu',name='fc1'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "#         optimizer=Adam(),                  \n",
    "        optimizer=SGD(lr=0.01, momentum=0.5, decay=0.0, nesterov=False), \n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['acc'])\n",
    "    \n",
    "    return model, description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "\n",
      "Fold:  0\n",
      "--Last epoch validation accuracy: 80.51%\n",
      "--Best model validation accuracy: 81.36%\n",
      "\n",
      "Fold:  1\n",
      "--Last epoch validation accuracy: 78.81%\n",
      "--Best model validation accuracy: 77.97%\n",
      "\n",
      "Fold:  2\n",
      "--Last epoch validation accuracy: 77.97%\n",
      "--Best model validation accuracy: 81.36%\n",
      "\n",
      "Fold:  3\n",
      "--Last epoch validation accuracy: 74.58%\n",
      "--Best model validation accuracy: 77.12%\n",
      "\n",
      "Fold:  4\n",
      "--Last epoch validation accuracy: 74.58%\n",
      "--Best model validation accuracy: 73.73%\n",
      "\n",
      "Fold:  5\n",
      "--Last epoch validation accuracy: 78.81%\n",
      "--Best model validation accuracy: 78.81%\n",
      "\n",
      "Fold:  6\n",
      "--Last epoch validation accuracy: 73.73%\n",
      "--Best model validation accuracy: 73.73%\n",
      "\n",
      "Fold:  7\n",
      "--Last epoch validation accuracy: 85.59%\n",
      "--Best model validation accuracy: 83.90%\n",
      "\n",
      "Fold:  8\n",
      "--Last epoch validation accuracy: 75.86%\n",
      "--Best model validation accuracy: 79.31%\n",
      "\n",
      "Fold:  9\n",
      "--Last epoch validation accuracy: 74.14%\n",
      "--Best model validation accuracy: 75.86%\n",
      "\n",
      "\n",
      "Best models average validation accuracy: 0.783139\n",
      "Best models standard deviation of accuracy: 0.031709\n",
      "Iteration 1 time: 480.49 seconds\n",
      "\n",
      "\n",
      "Iteration 2\n",
      "\n",
      "Fold:  0\n",
      "--Last epoch validation accuracy: 78.81%\n",
      "--Best model validation accuracy: 82.20%\n",
      "\n",
      "Fold:  1\n",
      "--Last epoch validation accuracy: 79.66%\n",
      "--Best model validation accuracy: 79.66%\n",
      "\n",
      "Fold:  2\n",
      "--Last epoch validation accuracy: 81.36%\n",
      "--Best model validation accuracy: 81.36%\n",
      "\n",
      "Fold:  3\n",
      "--Last epoch validation accuracy: 80.51%\n",
      "--Best model validation accuracy: 76.27%\n",
      "\n",
      "Fold:  4\n",
      "--Last epoch validation accuracy: 77.97%\n",
      "--Best model validation accuracy: 77.12%\n",
      "\n",
      "Fold:  5\n",
      "--Last epoch validation accuracy: 81.36%\n",
      "--Best model validation accuracy: 79.66%\n",
      "\n",
      "Fold:  6\n",
      "--Last epoch validation accuracy: 78.81%\n",
      "--Best model validation accuracy: 77.97%\n",
      "\n",
      "Fold:  7\n",
      "--Last epoch validation accuracy: 87.29%\n",
      "--Best model validation accuracy: 85.59%\n",
      "\n",
      "Fold:  8\n",
      "--Last epoch validation accuracy: 77.59%\n",
      "--Best model validation accuracy: 78.45%\n",
      "\n",
      "Fold:  9\n",
      "--Last epoch validation accuracy: 78.45%\n",
      "--Best model validation accuracy: 74.14%\n",
      "\n",
      "\n",
      "Best models average validation accuracy: 0.792417\n",
      "Best models standard deviation of accuracy: 0.030915\n",
      "Iteration 2 time: 555.7 seconds\n",
      "\n",
      "\n",
      "Iteration 3\n",
      "\n",
      "Fold:  0\n",
      "--Last epoch validation accuracy: 83.90%\n",
      "--Best model validation accuracy: 82.20%\n",
      "\n",
      "Fold:  1\n",
      "--Last epoch validation accuracy: 76.27%\n",
      "--Best model validation accuracy: 81.36%\n",
      "\n",
      "Fold:  2\n",
      "--Last epoch validation accuracy: 78.81%\n",
      "--Best model validation accuracy: 80.51%\n",
      "\n",
      "Fold:  3\n",
      "--Last epoch validation accuracy: 78.81%\n",
      "--Best model validation accuracy: 79.66%\n",
      "\n",
      "Fold:  4\n",
      "--Last epoch validation accuracy: 73.73%\n",
      "--Best model validation accuracy: 73.73%\n",
      "\n",
      "Fold:  5\n",
      "--Last epoch validation accuracy: 72.03%\n",
      "--Best model validation accuracy: 81.36%\n",
      "\n",
      "Fold:  6\n",
      "--Last epoch validation accuracy: 72.88%\n",
      "--Best model validation accuracy: 77.97%\n",
      "\n",
      "Fold:  7\n",
      "--Last epoch validation accuracy: 83.05%\n",
      "--Best model validation accuracy: 83.05%\n",
      "\n",
      "Fold:  8\n",
      "--Last epoch validation accuracy: 77.59%\n",
      "--Best model validation accuracy: 79.31%\n",
      "\n",
      "Fold:  9\n"
     ]
    }
   ],
   "source": [
    "model = conv_2D\n",
    "\n",
    "number_of_iterations = 3\n",
    "\n",
    "avg_accuracies = []\n",
    "std_accuracies = []\n",
    "\n",
    "for iteration in range(0, number_of_iterations):\n",
    "    iteration_number = iteration + 1 \n",
    "    print(\"Iteration\", iteration_number)\n",
    "    start_time = time()\n",
    "    \n",
    "    score, best_model_score = run_pipeline(create_model=model,\n",
    "                                           folds=folds,\n",
    "#                                            x=x,\n",
    "                                           x=x3d,\n",
    "                                           y=y,\n",
    "                                           epochs=300)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    accuracy = [row[1] for row in best_model_score]\n",
    "\n",
    "    avg_accuracy = np.mean(accuracy)\n",
    "    print(\"Best models average validation accuracy: {}\".format(round(avg_accuracy, 6)))\n",
    "\n",
    "    std_accuracy = np.std(accuracy)\n",
    "    print(\"Best models standard deviation of accuracy: {}\".format(round(std_accuracy, 6)))\n",
    "    \n",
    "    avg_accuracies.append(avg_accuracy)\n",
    "    std_accuracies.append(std_accuracy)\n",
    "    \n",
    "    print(\"Iteration\", iteration_number, \"time:\", end_time(start_time), \"seconds\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n",
    "grand_mean_avg = np.mean(avg_accuracies)\n",
    "grand_mean_std = np.mean(std_accuracies)\n",
    "print(\"~~~Grand mean of average accuracy: {}\".format(round(grand_mean_avg, 6)))\n",
    "print(\"~~~Grand mean of standard deviation accuracy: {}\".format(round(grand_mean_std, 6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(history):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "# plot_results(history)\n",
    "# using view in tensorboard instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots_printer import draw_plots, draw_plots_with_chunks\n",
    "from data_reader import load_input_data, prepare_chunks\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [20, 5]\n",
    "\n",
    "FREQUENCY_TO_SAMPLING_RATIO = 100\n",
    "\n",
    "input_data, target, headers = load_input_data(CHUNK_SIZE_IN_SECONDS)\n",
    "chunks_input, chunks_target = prepare_chunks(input_data, \n",
    "                                            target, \n",
    "                                            chunk_size_in_seconds=CHUNK_SIZE_IN_SECONDS, \n",
    "                                            ratio=FREQUENCY_TO_SAMPLING_RATIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_plots(input_data, \n",
    "           target, \n",
    "           headers, \n",
    "           patient=0, \n",
    "           start_second=900, \n",
    "           end_second=910,\n",
    "           ratio=FREQUENCY_TO_SAMPLING_RATIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_plots_with_chunks(input_data, target, headers, patient=0, chunks_input = chunks_input, to_pdf=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
