{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "* test data as whole, not couple of chunks\n",
    "* visualisation for diagnosing\n",
    "* saving output of training to file\n",
    "\n",
    "\n",
    "Architectures:\n",
    "* cnn + lstm: https://stats.stackexchange.com/questions/252095/sequence-classification-via-neural-networks\n",
    "* user models from keras applications: https://keras.io/applications/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#display all values from array\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "#display not in scientific format\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Flatten, Dropout, LSTM, GRU, BatchNormalization, Activation\n",
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "from keras import callbacks\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "CHUNK_SIZE_IN_SECONDS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import datetime\n",
    "\n",
    "def create_current_time():\n",
    "    timestamp = time()\n",
    "    return datetime.datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "def end_time(start_time):\n",
    "    end_time = time() - start_time\n",
    "    return round(end_time, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "def get_function_name():\n",
    "    return inspect.stack()[1][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_reader import get_data\n",
    "\n",
    "def load_data_kfold(folds_number, test_size=0.05):\n",
    "    x, y = get_data(CHUNK_SIZE_IN_SECONDS)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, \n",
    "                                                        y, \n",
    "                                                        test_size=test_size)\n",
    "    \n",
    "    folds = list(StratifiedKFold(n_splits=folds_number, \n",
    "                                 shuffle=True, \n",
    "                                 random_state=1).split(x_train, y_train))\n",
    "    \n",
    "    return folds, x_train, y_train, x_test, y_test\n",
    "\n",
    "def load_data_train_test(test_size=0.05):\n",
    "    x, y = get_data(CHUNK_SIZE_IN_SECONDS)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, \n",
    "                                                        y, \n",
    "                                                        test_size=test_size)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):    \n",
    "    initial_lrate=0.1\n",
    "    drop=0.6\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    \n",
    "    return lrate\n",
    "\n",
    "\n",
    "def callbacks_list(description): \n",
    "    return [\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_acc', \n",
    "        patience=30\n",
    "    ),\n",
    "    callbacks.LearningRateScheduler(step_decay),\n",
    "        \n",
    "    callbacks.ModelCheckpoint(\n",
    "        filepath='tmp/best_model.h5', \n",
    "        monitor='val_acc',\n",
    "        save_best_only=True\n",
    "    ),\n",
    "    callbacks.TensorBoard(\n",
    "        log_dir='tmp/logs/{}. {}'.format(description, create_current_time()),\n",
    "        histogram_freq=0, #it has to be 0, otherwise throws error during training\n",
    "        write_graph=True,\n",
    "        write_images=True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(create_model, folds, x, y, epochs):\n",
    "    score = []\n",
    "    best_model_score = []\n",
    "    \n",
    "    for fold_number, (train_idx, val_idx) in enumerate(folds):\n",
    "        print('\\nFold: ', fold_number)\n",
    "        x_train_cv = x[train_idx]\n",
    "        y_train_cv = y[train_idx]\n",
    "        x_valid_cv = x[val_idx]\n",
    "        y_valid_cv = y[val_idx]\n",
    "                \n",
    "        input_shape = x.shape[1:]\n",
    "\n",
    "        model, model_description = create_model(input_shape)\n",
    "\n",
    "        callbacks = callbacks_list(\"{}. Fold: {}.\".format(model_description, \n",
    "                                                          fold_number))\n",
    "\n",
    "        history = model.fit(x_train_cv,\n",
    "                            y_train_cv,\n",
    "                            epochs=epochs,\n",
    "                            batch_size=16,\n",
    "                            callbacks=callbacks,\n",
    "                            validation_data=(x_valid_cv, y_valid_cv),\n",
    "                            verbose=0)\n",
    "\n",
    "        score.append(model.evaluate(x_valid_cv, y_valid_cv, batch_size=16, verbose=0))\n",
    "\n",
    "        model.load_weights(\"tmp/best_model.h5\")\n",
    "        best_model_score.append(model.evaluate(x_valid_cv, y_valid_cv, batch_size=16, verbose=0))\n",
    "        \n",
    "#         print(\"--Last epoch validation accuracy: %.2f%%\" % (score[fold_number][1]*100))\n",
    "        print(\"--Best model validation accuracy: %.2f%%\" % (best_model_score[fold_number][1]*100))\n",
    "        \n",
    "    return score, best_model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds, x_train, y_train, x_test, y_test = load_data_kfold(folds_number=10)\n",
    "\n",
    "# add dimmension for conv2d\n",
    "x_train_3d = x_train\n",
    "x_train_3d = np.expand_dims(x_train_3d, axis=3)\n",
    "\n",
    "x_test_3d = x_test\n",
    "x_test_3d = np.expand_dims(x_test_3d, axis=3)\n",
    "\n",
    "# x_train, y_train, x_test, y_test = load_data_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#78%\n",
    "# lr decay disabled\n",
    "def conv_1D_smaller_32_16_with_adam(input_shape):\n",
    "    description = get_function_name()\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=6, padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(Conv1D(filters=16, kernel_size=6, padding='same', activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "#     lr=3e-5\n",
    "    model.compile(\n",
    "        optimizer=Adam(),                  \n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['acc'])\n",
    "    \n",
    "    return model, description\n",
    "\n",
    "# 80%\n",
    "def conv1D_with_batch(input_shape):\n",
    "    description = get_function_name()\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=6, padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=6, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(Conv1D(filters=32, kernel_size=6, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64,activation = 'relu',name='fc0'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(32,activation = 'relu',name='fc1'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "                optimizer=SGD(lr=0.01, momentum=0.5, decay=0.0, nesterov=False), \n",
    "\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['acc'])\n",
    "    \n",
    "    return model, description\n",
    "\n",
    "\n",
    "def conv_2D_test(input_shape):\n",
    "    description = get_function_name()\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(64,(3,3),strides = (1,1),name='layer_conv1',padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2,2),name='maxPool1'))\n",
    "    \n",
    "    model.add(Conv2D(64,(3,3),strides = (1,1),name='layer_conv2',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2,2),name='maxPool2'))\n",
    "    \n",
    "    model.add(Conv2D(32,(3,3),strides = (1,1),name='conv3',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2,2),name='maxPool3'))\n",
    "    \n",
    "#     model.add(LSTM(100))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64,activation = 'relu',name='fc0'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(32,activation = 'relu',name='fc1'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(              \n",
    "        optimizer=SGD(lr=0.01, momentum=0.5, decay=0.0, nesterov=False), \n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['acc'])\n",
    "    \n",
    "    return model, description\n",
    "\n",
    "#  < 80% long training\n",
    "def conv1D_lstm(input_shape):\n",
    "    description = get_function_name()\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=6, padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=6, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(Conv1D(filters=32, kernel_size=6, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(LSTM(100))\n",
    "    \n",
    "#     model.add(Flatten())\n",
    "    model.add(Dense(64,activation = 'relu',name='fc0'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(32,activation = 'relu',name='fc1'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "                optimizer=SGD(lr=0.01, momentum=0.5, decay=0.0, nesterov=False), \n",
    "\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['acc'])\n",
    "    \n",
    "    return model, description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST ONE\n",
    "# 80%\n",
    "# lr decay callback enabled\n",
    "def conv_2D(input_shape):\n",
    "    description = get_function_name()\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(64,(3,3),strides = (1,1),name='layer_conv1',padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2,2),name='maxPool1'))\n",
    "    \n",
    "    model.add(Conv2D(64,(3,3),strides = (1,1),name='layer_conv2',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2,2),name='maxPool2'))\n",
    "    \n",
    "    model.add(Conv2D(32,(3,3),strides = (1,1),name='conv3',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2,2),name='maxPool3'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64,activation = 'relu',name='fc0'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(32,activation = 'relu',name='fc1'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(              \n",
    "        optimizer=SGD(lr=0.01, momentum=0.5, decay=0.0, nesterov=False), \n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['acc'])\n",
    "    \n",
    "    return model, description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model(model, x):\n",
    "    model, description = model(x.shape[1:])\n",
    "    print(\"Model:\", description)\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_41 (Flatten)         (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 1000)              3201000   \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 30)                30030     \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 3,231,061\n",
      "Trainable params: 3,231,061\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Iteration 1\n",
      "\n",
      "Fold:  0\n",
      "--Best model validation accuracy: 51.79%\n",
      "\n",
      "Fold:  1\n",
      "--Best model validation accuracy: 50.00%\n",
      "\n",
      "Fold:  2\n",
      "--Best model validation accuracy: 50.00%\n",
      "\n",
      "Fold:  3\n",
      "--Best model validation accuracy: 50.89%\n",
      "\n",
      "Fold:  4\n",
      "--Best model validation accuracy: 50.89%\n",
      "\n",
      "Fold:  5\n",
      "--Best model validation accuracy: 50.00%\n",
      "\n",
      "Fold:  6\n",
      "--Best model validation accuracy: 50.00%\n",
      "\n",
      "Fold:  7\n",
      "--Best model validation accuracy: 52.25%\n",
      "\n",
      "Fold:  8\n",
      "--Best model validation accuracy: 50.45%\n",
      "\n",
      "Fold:  9\n",
      "--Best model validation accuracy: 50.45%\n",
      "\n",
      "\n",
      "Best models average validation accuracy: 0.506725\n",
      "Best models standard deviation of accuracy: 0.007576\n",
      "Iteration 1 time: 132.92 seconds\n",
      "\n",
      "\n",
      "~~~Grand mean of average accuracy: 0.506725\n",
      "~~~Grand mean of standard deviation accuracy: 0.007576\n"
     ]
    }
   ],
   "source": [
    "model = dense\n",
    "print_model(model, x_train_3d)\n",
    "\n",
    "number_of_iterations = 1\n",
    "\n",
    "avg_accuracies = []\n",
    "std_accuracies = []\n",
    "\n",
    "for iteration in range(0, number_of_iterations):\n",
    "    iteration_number = iteration + 1 \n",
    "    print(\"Iteration\", iteration_number)\n",
    "    start_time = time()\n",
    "    \n",
    "    score, best_model_score = run_pipeline(create_model=model,\n",
    "                                           folds=folds,\n",
    "#                                            x=x_train,\n",
    "                                           x=x_train_3d,\n",
    "                                           y=y_train,\n",
    "                                           epochs=100)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    accuracy = [row[1] for row in best_model_score]\n",
    "\n",
    "    avg_accuracy = np.mean(accuracy)\n",
    "    print(\"Best models average validation accuracy: {}\".format(round(avg_accuracy, 6)))\n",
    "\n",
    "    std_accuracy = np.std(accuracy)\n",
    "    print(\"Best models standard deviation of accuracy: {}\".format(round(std_accuracy, 6)))\n",
    "    \n",
    "    avg_accuracies.append(avg_accuracy)\n",
    "    std_accuracies.append(std_accuracy)\n",
    "    \n",
    "    print(\"Iteration\", iteration_number, \"time:\", end_time(start_time), \"seconds\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n",
    "grand_mean_avg = np.mean(avg_accuracies)\n",
    "grand_mean_std = np.mean(std_accuracies)\n",
    "print(\"~~~Grand mean of average accuracy: {}\".format(round(grand_mean_avg, 6)))\n",
    "print(\"~~~Grand mean of standard deviation accuracy: {}\".format(round(grand_mean_std, 6)))\n",
    "\n",
    "# todo: run on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bad models\n",
    "\n",
    "# bad\n",
    "def cnn_lstm(input_shape):\n",
    "    description = get_function_name()\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=6, padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(Conv1D(filters=16, kernel_size=6, padding='same', activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(LSTM(100))\n",
    "    \n",
    "#     model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer=RMSprop(lr=3e-5),\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['acc'])\n",
    "    \n",
    "    return model, description\n",
    "\n",
    "\n",
    "def dense(input_shape):\n",
    "    description = get_function_name()\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=input_shape))\n",
    "    model.add(Dense(1000, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    \n",
    "    sgd = SGD(lr=0.1, momentum=0.9, decay=0.0, nesterov=False)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "#     model.compile(optimizer=RMSprop(lr=3e-5),\n",
    "#                       loss='binary_crossentropy',\n",
    "#                       metrics=['acc'])\n",
    "    \n",
    "    return model, description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(history):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "# plot_results(history)\n",
    "# using view in tensorboard instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots_printer import draw_plots, draw_plots_with_chunks\n",
    "from data_reader import load_input_data, prepare_chunks\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [20, 5]\n",
    "\n",
    "FREQUENCY_TO_SAMPLING_RATIO = 100\n",
    "\n",
    "input_data, target, headers = load_input_data(CHUNK_SIZE_IN_SECONDS)\n",
    "chunks_input, chunks_target = prepare_chunks(input_data, \n",
    "                                            target, \n",
    "                                            chunk_size_in_seconds=CHUNK_SIZE_IN_SECONDS, \n",
    "                                            ratio=FREQUENCY_TO_SAMPLING_RATIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_plots(input_data, \n",
    "           target, \n",
    "           headers, \n",
    "           patient=0, \n",
    "           start_second=900, \n",
    "           end_second=910,\n",
    "           ratio=FREQUENCY_TO_SAMPLING_RATIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_plots_with_chunks(input_data, target, headers, patient=0, chunks_input = chunks_input, to_pdf=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
