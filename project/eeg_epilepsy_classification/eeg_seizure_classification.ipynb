{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "* modify pipeline, more options\n",
    "* test data as whole, not couple of chunks\n",
    "* visualisation for diagnosing\n",
    "\n",
    "\n",
    "Architectures:\n",
    "* conv2d\n",
    "* cnn + lstm: https://stats.stackexchange.com/questions/252095/sequence-classification-via-neural-networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "#display all values from array\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "#display not in scientific format\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# from tensorflow import set_random_seed\n",
    "# set_random_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, LSTM, BatchNormalization, Activation\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras import callbacks\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "CHUNK_SIZE_IN_SECONDS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import datetime\n",
    "\n",
    "def create_current_time():\n",
    "    timestamp = time()\n",
    "    return datetime.datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callbacks_list(description): \n",
    "    return [\n",
    "#     callbacks.EarlyStopping(\n",
    "#         monitor='val_acc', \n",
    "#         patience=5\n",
    "#     ),\n",
    "    callbacks.ModelCheckpoint(\n",
    "        filepath='tmp/best_model.h5', \n",
    "        monitor='val_loss', \n",
    "        save_best_only=True\n",
    "    ),\n",
    "    callbacks.TensorBoard(\n",
    "        log_dir='tmp/logs/{}:{}'.format(description, create_current_time()),\n",
    "        histogram_freq=0, #it has to be 0, otherwise throws error during training\n",
    "        write_graph=True,\n",
    "        write_images=True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "def get_function_name():\n",
    "    return inspect.stack()[1][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_reader import get_data\n",
    "\n",
    "def load_data_kfold(folds_number):\n",
    "    x, y = get_data(CHUNK_SIZE_IN_SECONDS)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, \n",
    "                                                        y, \n",
    "                                                        test_size=0.05)\n",
    "    \n",
    "    folds = list(StratifiedKFold(n_splits=folds_number, \n",
    "                                 shuffle=True, \n",
    "                                 random_state=1).split(x_train, y_train))\n",
    "    \n",
    "    return folds, x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~70-80% test, overfitting\n",
    "def conv_1D_62_32(input_shape):\n",
    "    description = get_function_name()\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=6, padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model, description\n",
    "\n",
    "#less overfitting\n",
    "def conv_1D_smaller_32_16(input_shape):\n",
    "    description = get_function_name()\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=6, padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(Conv1D(filters=16, kernel_size=6, padding='same', activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model, description\n",
    "\n",
    "\n",
    "def testing(input_shape):\n",
    "    description = get_function_name()\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=6, padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv1D(filters=16, kernel_size=6, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model, description\n",
    "\n",
    "\n",
    "def baseline(input_shape):\n",
    "    description = get_function_name()\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, kernel_initializer='normal', activation='relu', input_shape=input_shape))\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    sgd = SGD(lr=0.1, momentum=0.9, decay=0.0, nesterov=False)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    return model, description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(create_model, folds, epochs, learning_rate):\n",
    "    score = []\n",
    "    best_model_score = []\n",
    "    \n",
    "    for fold_number, (train_idx, val_idx) in enumerate(folds):\n",
    "        print('\\nFold: ', fold_number + 1)\n",
    "        x_train_cv = x_train[train_idx]\n",
    "        y_train_cv = y_train[train_idx]\n",
    "        x_valid_cv = x_train[val_idx]\n",
    "        y_valid_cv = y_train[val_idx]\n",
    "                \n",
    "        input_shape = x_train.shape[1:]\n",
    "\n",
    "        model, model_description = create_model(input_shape)\n",
    "        \n",
    "        description = \"lr = {}\".format(learning_rate)\n",
    "\n",
    "        callbacks = callbacks_list(\"{}. {}-{}\".format(model_description, \n",
    "                                                      description, \n",
    "                                                      fold_number))\n",
    "\n",
    "        model.compile(optimizer=RMSprop(lr=learning_rate),\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['acc'])\n",
    "\n",
    "        history = model.fit(x_train_cv,\n",
    "                            y_train_cv,\n",
    "                            epochs=epochs,\n",
    "                            batch_size=16,\n",
    "                            callbacks=callbacks,\n",
    "                            validation_data=(x_valid_cv, y_valid_cv),\n",
    "                            verbose=0)\n",
    "\n",
    "        score.append(model.evaluate(x_valid_cv, y_valid_cv, batch_size=16, verbose=0))\n",
    "\n",
    "        model.load_weights(\"tmp/best_model.h5\")\n",
    "        best_model_score.append(model.evaluate(x_valid_cv, y_valid_cv, batch_size=16, verbose=0))\n",
    "        \n",
    "        print(\"--Last epoch validation accuracy: %.2f%%\" % (score[fold_number][1]*100))\n",
    "        print(\"--Best model validation accuracy: %.2f%%\" % (best_model_score[fold_number][1]*100))\n",
    "        \n",
    "    return score, best_model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds, x_train, y_train, x_test, y_test = load_data_kfold(folds_number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold:  1\n",
      "--Last epoch validation accuracy: 74.11%\n",
      "--Best model validation accuracy: 75.89%\n",
      "\n",
      "Fold:  2\n",
      "--Last epoch validation accuracy: 75.00%\n",
      "--Best model validation accuracy: 75.89%\n",
      "\n",
      "Fold:  3\n",
      "--Last epoch validation accuracy: 67.86%\n",
      "--Best model validation accuracy: 59.82%\n",
      "\n",
      "Fold:  4\n",
      "--Last epoch validation accuracy: 74.11%\n",
      "--Best model validation accuracy: 74.11%\n",
      "\n",
      "Fold:  5\n",
      "--Last epoch validation accuracy: 80.36%\n",
      "--Best model validation accuracy: 75.89%\n",
      "\n",
      "Fold:  6\n",
      "--Last epoch validation accuracy: 71.43%\n",
      "--Best model validation accuracy: 73.21%\n",
      "\n",
      "Fold:  7\n",
      "--Last epoch validation accuracy: 76.79%\n",
      "--Best model validation accuracy: 79.46%\n",
      "\n",
      "Fold:  8\n",
      "--Last epoch validation accuracy: 75.00%\n",
      "--Best model validation accuracy: 75.89%\n",
      "\n",
      "Fold:  9\n",
      "--Last epoch validation accuracy: 63.06%\n",
      "--Best model validation accuracy: 63.96%\n",
      "\n",
      "Fold:  10\n",
      "--Last epoch validation accuracy: 77.27%\n",
      "--Best model validation accuracy: 78.18%\n",
      "Average best models validation accuracy: 0.732324353897517\n"
     ]
    }
   ],
   "source": [
    "score, best_model_score = run_pipeline(create_model=conv_1D_smaller_32_16,\n",
    "                                       folds=folds,\n",
    "                                       epochs=100,\n",
    "                                       learning_rate=3e-5)\n",
    "\n",
    "avg_accuracy = np.mean([row[1] for row in best_model_score])\n",
    "print(\"Average best models validation accuracy: {}\".format(avg_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-bc5da312afc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;31m# using view in tensorboard instead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_results(history):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "# plot_results(history)\n",
    "# using view in tensorboard instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots_printer import draw_plots, draw_plots_with_chunks\n",
    "from data_reader import load_input_data, prepare_chunks\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [20, 5]\n",
    "\n",
    "input_data, target, headers = load_input_data()\n",
    "chunks_input, chunks_target = prepare_chunks(input_data, \n",
    "                                            target, \n",
    "                                            chunk_size_in_seconds=CHUNK_SIZE_IN_SECONDS, \n",
    "                                            ratio=FREQUENCY_TO_SAMPLING_RATIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_plots(input_data, \n",
    "           target, \n",
    "           headers, \n",
    "           patient=0, \n",
    "           start_second=900, \n",
    "           end_second=910,\n",
    "           ratio=FREQUENCY_TO_SAMPLING_RATIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_plots_with_chunks(input_data, target, headers, patient=0, chunks_input = chunks_input, to_pdf=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
